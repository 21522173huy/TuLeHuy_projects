{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install --upgrade transformers\n","!pip install --upgrade nltk\n","!pip install -q evaluate\n","!pip install bert-score\n","!pip install -q rouge_score\n","!pip install -q git+https://github.com/salaniz/pycocoevalcap.git"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","nltk.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","# device will determine whether to run the training on GPU or CPU.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.cuda.device_count()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def count_params(model):\n","  return sum(p.numel() for p in model.parameters() if p.requires_grad)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration, BeitImageProcessor, AutoModel\n","\n","# Vision\n","vision_module = 'microsoft/beit-base-patch16-224-pt22k-ft22k'\n","feature_extractor = BeitImageProcessor.from_pretrained(vision_module)\n","\n","# Language\n","language_module = 'luqh/ClinicalT5-base'\n","tokenizer = T5Tokenizer.from_pretrained(language_module)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import glob\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from PIL import Image\n","from torch.utils.data import Dataset\n","from sklearn.model_selection import train_test_split\n","import torchvision.transforms as transforms\n","import pickle\n","\n","class ImageCLEF(Dataset):\n","  def __init__(self, tokenizer = None,\n","               feature_extractor = None,\n","               image_folder = None,\n","               data_csv_path = None,\n","               one_hot_path = None,\n","               cuis_mapping = None, \n","               data=None):\n","\n","    self.tokenizer = tokenizer\n","    self.feature_extractor = feature_extractor\n","\n","    # if data is None all others argument cant be None\n","    assert (tokenizer is not None\n","            and feature_extractor is not None\n","            and image_folder is not None\n","            and data_csv_path is not None\n","            and one_hot_path is not None \n","#            and cuis_mapping is not None\n","           ) or data is not None, \"All other arguments must be passed if data is None!\"\n","\n","    if data is None:\n","      self.load_data(image_folder, data_csv_path, one_hot_path)\n","    else:\n","      self.data = data\n","\n","  def load_data(self, image_folder, data_csv_path, one_hot_path):\n","\n","    with open(one_hot_path, 'rb') as file:\n","      one_hot = pickle.load(file)\n","\n","    self.one_hot = one_hot\n","    self.data = []\n","\n","    data_csv = pd.read_csv(data_csv_path)\n","\n","    # Setup the total feature file\n","    image_paths = glob.glob(image_folder + '/*')\n","\n","    image_ids_list = list(data_csv['ID'])\n","\n","    for path in tqdm(image_paths):\n","\n","      # Obtaining Image Id\n","      image_id = path.split('/')[-1].split('.')[0]\n","\n","      if image_id in image_ids_list:\n","\n","        # Mapping image id with other variables\n","        # caption = data_csv[data_csv['image_id'] == image_id]['caption'].item()\n","        caption = data_csv[data_csv['ID'] == image_id]['non_stopwords'].item()\n","        label_one_hot = data_csv[data_csv['ID'] == image_id]['labels'].item()\n","        label_id = data_csv[data_csv['ID'] == image_id]['CUIs'].item()\n","        label_name = data_csv[data_csv['ID'] == image_id]['Canonical_name'].item()\n","\n","        sample = {\n","            'image_id': image_id,\n","            'path' : path,\n","            'captions': caption,\n","            'label_id': label_id,\n","            'label_one_hot' : label_one_hot,\n","            'label_name' : label_name\n","        }\n","\n","        self.data.append(sample)\n","\n","      else : continue\n","\n","  def num_classes(self):\n","    return len(self.one_hot.classes_)\n","\n","  def get_classes(self):\n","    return self.one_hot.classes_\n","\n","  def __getitem__(self, idx):\n","    sample = self.data[idx]\n","\n","    return {\n","      'image_id': sample['image_id'],\n","      'path' : sample['path'],\n","      'captions': sample['captions'],\n","      'label_id': sample['label_id'],\n","      'label_one_hot' : sample['label_one_hot'],\n","      'label_name' : sample['label_name']\n","    }\n","\n","  def split_data(self, validation_size, random_state=42):\n","\n","    # Split train and evaluation set\n","    train_data, val_data = train_test_split(self.data,\n","                                                 test_size=validation_size,\n","                                                 random_state=random_state)\n","\n","    return (ImageCLEF(tokenizer=self.tokenizer, data=train_data),\n","            ImageCLEF(tokenizer=self.tokenizer, data=val_data))\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def collate_fn(self, batch):\n","\n","    label_one_hot = [each['label_one_hot'] for each in batch]\n","    label_id = [each['label_id'] for each in batch]\n","    label_name = [each['label_name'].split(\"['\")[-1].split(\"']\")[0].replace(\"'\", \"\") for each in batch]\n","\n","    images = [Image.open(each['path']).convert('RGB') for each in batch]\n","\n","    raw_captions = [each['captions'] for each in batch]\n","    image_ids = [each['image_id'] for each in batch]\n","\n","    extracted_images = self.feature_extractor(images = images, return_tensors = 'pt')\n","    tokenized_captions = self.tokenizer(raw_captions, padding = True, truncation = True, max_length = 128, return_tensors = 'pt')\n","    tokenized_label_name = self.tokenizer(label_name, padding = True, truncation = True, max_length = 128, return_tensors = 'pt')\n","\n","    sample = {\n","      'ids' : image_ids,\n","      'raw_captions' : raw_captions,\n","      'pixel_values' : extracted_images.pixel_values, # tensor\n","      'labels' : tokenized_captions.input_ids, # tensor\n","      'attention_mask' : tokenized_captions.attention_mask,\n","      'label_one_hot' : label_one_hot,\n","      'label_id' : label_id,\n","      'label_name' : label_name,\n","      'tokenized_label_name' : tokenized_label_name.input_ids,\n","      'tokenized_label_mask' : tokenized_label_name.attention_mask\n","    }\n","\n","    return sample"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = ImageCLEF(\n","    tokenizer = tokenizer,\n","    feature_extractor = feature_extractor,\n","    image_folder = '/kaggle/input/imageclef2024/train_images/train',\n","    data_csv_path = '/kaggle/input/imageclef2024/merged_captions_concepts_.csv',\n","#     data_csv_path = '/kaggle/input/imageclef2024/5000_merged_captions_concepts_.csv',\n","    one_hot_path = '/kaggle/input/imageclef2024/one_hot.pkl',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data, val_data = data.split_data(validation_size=0.0375)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True, collate_fn=data.collate_fn)\n","val_dataloader = DataLoader(val_data, batch_size=16, shuffle=False, collate_fn=data.collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from Captioning_Module import BeIT_T5_Concepts"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = nn.DataParallel(BeIT_T5_Concepts(vision_module = vision_module, \n","                                language_module = language_module, \n","                                device= device))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import evaluate\n","import numpy as np\n","\n","meteor = evaluate.load('meteor')\n","rouge = evaluate.load('rouge')\n","bleu = evaluate.load(\"bleu\")\n","bertscore = evaluate.load(\"bertscore\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def ignore_padding(outputs, labels, padding_values = 1):\n","\n","  mask = labels != padding_values\n","\n","  new_outputs, new_labels = [], []\n","\n","  for i, each in enumerate(mask):\n","    ignore_outputs = outputs[i][each]\n","    ignore_labels = labels[i][each]\n","\n","    new_outputs.append(ignore_outputs), new_labels.append(ignore_labels)\n","\n","  return new_outputs, new_labels\n","\n","def convert_prediction(outputs):\n","  res = []\n","\n","  for each in outputs:\n","    get = each.argmax(dim = -1)\n","    res.append(get)\n","\n","  return res\n","\n","def convert_ids_to_string(ids, tokenizer):\n","\n","  new_ids = ids.copy()\n","\n","  if new_ids[0].dim() == 2: # prediction\n","    new_ids = convert_prediction(new_ids) # batch_size, seq_len\n","\n","  return [tokenizer.decode(id) for id in new_ids]\n","\n","def compute_accuracy(outputs_, labels_, padding_idx):\n","\n","  arg_max_outputs = convert_prediction(outputs_)\n","\n","  flat_output_ = []\n","  flat_labels_ = []\n","\n","  for output, label in zip(arg_max_outputs, labels_):\n","    flat_output_.extend(output), flat_labels_.extend(label)\n","\n","  flat_output_ = torch.tensor(flat_output_)\n","  flat_labels_ = torch.tensor(flat_labels_)\n","\n","  acc = (flat_output_ == flat_labels_).sum().item() / flat_labels_.shape[0]\n","  return acc\n","\n","def calculate_mean(numbers):\n","    total = sum(numbers)\n","    count = len(numbers)\n","    mean = total / count\n","    return mean\n","\n","def compute_metrics(outputs, label_ids, tokenizer):\n","\n","  outputs_, labels_ = ignore_padding(outputs, label_ids, tokenizer.pad_token_id)\n","\n","  pred_ans = convert_ids_to_string(outputs_, tokenizer)\n","  ground_t = convert_ids_to_string(labels_, tokenizer)\n","\n","  print(f'Prediction : {pred_ans}')\n","  print(f'Ground_truth : {ground_t}')\n","  print('       ')\n","\n","  # Compute Accuracy\n","  accuracy_score = compute_accuracy(outputs_, labels_, tokenizer.pad_token_id)\n","\n","  # Compute BLEU, ROUGE, METEOR\n","  bleu1_score = bleu.compute(predictions=pred_ans, references=ground_t, max_order=1)['bleu']\n","  bleu2_score = bleu.compute(predictions=pred_ans, references=ground_t, max_order=2)['bleu']\n","  bleu3_score = bleu.compute(predictions=pred_ans, references=ground_t, max_order=3)['bleu']\n","  bleu4_score = bleu.compute(predictions=pred_ans, references=ground_t, max_order=4)['bleu']\n","  rouge_score = rouge.compute(predictions=pred_ans, references=ground_t)['rougeL']\n","  meteor_score = meteor.compute(predictions=pred_ans, references=ground_t)['meteor']\n","\n","  # Compute Bert Score\n","  bert_score = bertscore.compute(predictions=pred_ans, references=ground_t, model_type = 'microsoft/deberta-xlarge-mnli', device = device)\n","  bert_score_F1_mean = calculate_mean(bert_score['f1'])\n","\n","  return np.array([bert_score_F1_mean, accuracy_score, bleu1_score, bleu2_score, bleu3_score, bleu4_score, rouge_score, meteor_score])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm.auto import tqdm\n","import os\n","\n","def process_data(model, dataloader, criterion, optimizer=None, compute_metrics=None, saved_metrics = None, scaler=None, device='cpu', padding_values = 0, epoch = 0, train_mode=True):\n","    total_loss = 0\n","    total_scores = 0\n","    total_samples = 0\n","    # count = 0\n","    \n","    flag = 'Val'\n","    if train_mode : \n","        flag = 'Train'\n","        \n","    save_part = 50\n","\n","    model.to(device)\n","    if train_mode:\n","        model.train()\n","    else:\n","        model.eval()\n","\n","    with torch.set_grad_enabled(train_mode):\n","        for i, samples in enumerate(tqdm(dataloader)):\n","\n","          # Forward\n","          # with torch.cuda.amp.autocast():\n","\n","          outputs = model(samples)\n","          loss = criterion(*outputs)\n","\n","          # Backward (for training)\n","          if train_mode:\n","              optimizer.zero_grad()\n","\n","              if scaler is not None:\n","                scaler.scale(loss).backward()\n","                scaler.step(optimizer)\n","                scaler.update()\n","              else:\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","                optimizer.step()\n","\n","            # Calculate score\n","          total_loss += loss.item()\n","          total_scores += compute_metrics(*outputs)\n","            \n","          if i%save_part == 0 and i != 0:\n","            saved_loss = total_loss/i\n","            saved_scores = total_scores/i\n","            \n","            if train_mode : \n","                torch.save(model.module.state_dict(), f'State_dict_BeIT5_Epoch_{epoch}_{i}.pth')\n","                \n","                if i/save_part > 1:\n","                    os.remove(f'State_dict_BeIT5_Epoch_{epoch}_{i-save_part}.pth')\n","                \n","            for idx, k in enumerate(saved_metrics.keys()):\n","                if k == 'loss':\n","                    saved_metrics[k].append(saved_loss)\n","                else : \n","                    saved_metrics[k].append(saved_scores[idx-1])\n","                    \n","            torch.save(saved_metrics, f'{flag}_Scores_BeIT5_Epoch_{epoch}_{i}.pth')\n","            \n","            if i/save_part > 1:\n","                os.remove(f'{flag}_Scores_BeIT5_Epoch_{epoch}_{i-save_part}.pth')\n","\n","    # if count == 0 : count = 1e-08\n","    total_loss /= len(dataloader)\n","    total_scores = total_scores /len(dataloader)\n","\n","    if len(total_scores) == 1:\n","      total_scores = (total_scores, )\n","\n","    if not isinstance(total_scores, tuple):\n","      total_scores = tuple(total_scores)\n","\n","    return (total_loss, ) + total_scores\n","\n","def print_metrics(metrics_dict, epoch, prefix=''):\n","    metric_strings = [f\"{key.capitalize()}: {value[epoch]:.4f}\" for key, value in metrics_dict.items()]\n","    print(f\"{prefix} -> {', '.join(metric_strings)}\")\n","\n","\n","def train_and_test(model, train_dataloader, test_dataloader, criterion, optimizer, compute_metrics, scaler, scheduler, epochs, padding_values, device):\n","\n","  train_metrics = {'loss': [], 'bert_score': [], 'accuracy': [], 'bleu1': [], 'bleu2': [], 'bleu3': [], 'bleu4': [], 'rouge': [], 'meteor': []}\n","  test_metrics = {'loss': [], 'bert_score': [], 'accuracy': [], 'bleu1': [], 'bleu2': [], 'bleu3': [], 'bleu4': [], 'rouge': [], 'meteor': []}\n","\n","  list_train_loss, list_test_loss = [], []\n","\n","  for epoch in range(epochs):\n","\n","    # Train data\n","    # process_data(model, dataloader, criterion, optimizer=None, compute_metrics=None, scaler=None, device='cpu', train_mode=True):\n","    scores = process_data(model=model,\n","                          dataloader=train_dataloader,\n","                          criterion=criterion,\n","                          optimizer=optimizer,\n","                          compute_metrics=compute_metrics,\n","                          saved_metrics = train_metrics,\n","                          scaler=None,\n","                          device=device,\n","                          padding_values = padding_values,\n","                          epoch = epoch,\n","                          train_mode=True)\n","\n","    # Save scores\n","    for i, k in enumerate(train_metrics.keys()):\n","      train_metrics[k].append(scores[i])\n","\n","    # Test data\n","    scores = process_data(model=model,\n","                          dataloader=test_dataloader,\n","                          criterion=criterion,\n","                          optimizer=optimizer,\n","                          compute_metrics=compute_metrics,\n","                          saved_metrics = test_metrics,\n","                          scaler=None,\n","                          device=device,\n","                          padding_values = padding_values,\n","                          epoch = epoch,\n","                          train_mode=False)\n","\n","    # Save scores\n","    for i, k in enumerate(test_metrics.keys()):\n","      test_metrics[k].append(scores[i])\n","\n","    # Using Scheduler\n","    scheduler.step(test_metrics['loss'][-1])\n","\n","    # Tracking\n","    print(f'Epoch {epoch}:')\n","    print_metrics(train_metrics, epoch, prefix='Train')\n","    print_metrics(test_metrics, epoch, prefix='Test')\n","\n","  return train_metrics, test_metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n","optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.01, lr = 2e-05)\n","cm = lambda outputs, labels: compute_metrics(outputs.mT, labels, tokenizer)\n","scaler = torch.cuda.amp.GradScaler()\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 2\n","train_metrics, test_metrics = train_and_test(model = model,\n","                                             train_dataloader = train_dataloader,\n","                                             test_dataloader = val_dataloader,\n","                                             criterion = criterion,\n","                                             optimizer = optimizer,\n","                                             compute_metrics = cm,\n","                                             scaler = scaler,\n","                                             scheduler = scheduler,\n","                                             epochs = epochs,\n","                                             padding_values = tokenizer.pad_token_id,\n","                                             device = device)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4898987,"sourceId":8255342,"sourceType":"datasetVersion"},{"sourceId":175927661,"sourceType":"kernelVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
